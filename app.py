import os
import replicate
import openai
import re
from flask import Flask, redirect, render_template, request, url_for

app = Flask(__name__)
openai.api_key = os.getenv("OPENAI_API_KEY")
style = ", concept art"


@app.route("/", methods=("GET", "POST")) # GET: requests data from server - POST: submit data to server.
def index():
    results = []
    if request.method == "POST":
        prompt_result = run_openai("text-davinci-002", default_sentence(),1).choices[0].text
        prompt = generate_prompt_lyrics(prompt_result)
        print("result:", prompt)
        response = run_openai("text-davinci-002", prompt,1) # Lyrics prompt generated by gpt-3
        result = response.choices[0].text
        return redirect(url_for("index", result=result, prompt = prompt_result))

    prompt = request.args.get("prompt")
    result = str(request.args.get("result"))
    [results.append(res) for res in chunks(result) if len(res) > 1] # Divide the lyrics in verse and add it to array
    if len(results) != 0:
        prompt_start = results[0] + style
        prompt_end = results[1] + style
        print("Start:", prompt_start, "End:", prompt_end)

    # Comment out sd module to prervent unnecessary runs
    """
    model = replicate.models.get("andreasjansson/stable-diffusion-animation")
    input = "https://replicate.com/api/models/andreasjansson/stable-diffusion-animation/files/fbeb1859-6cc1-4e1c-9f8b-64e74ed3f579/video.gif
    outputs = model.predict(
                prompt_start= prompt_start,
                prompt_end = prompt_end,
                prompt_strength = 0.8
                seed = 7829
                )
    output = [out for out in outputs]
    """
    return render_template("index.html", result=result, prompt = prompt)#, output = output)

def chunks (lyrics):
    #return str(re.findall('[a-zA-Z][^A-Z]*', lyrics))
    #return [s for s in re.split("([A-Z][^A-Z]*)", lyrics) if s]
    return str(lyrics).split("\n")

def run_openai (model, prompt, temperature):
    """
    Given a prompt, the model will return one or more predicted completions,
    and can also return the probabilities of alternative tokens at each position.

    args:
        model: ID of the model to use.
        prompt: The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.
        temperature: [0:1], bigger more creative applications, smaller for ones with a well-defined answer.
    """
    return openai.Completion.create(
            model= model,
            prompt= prompt,
            max_tokens = 128,
            temperature= temperature,
            )

def default_sentence ():
    return """ write a good idea for a song, what mood it is, the genre and bpm """

def generate_prompt_lyrics(result):
    return """Lyrics for {}""".format(result)
